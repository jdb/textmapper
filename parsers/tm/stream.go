// generated by Textmapper; DO NOT EDIT

package tm

import (
	"context"
	"fmt"

	"github.com/inspirer/textmapper/parsers/tm/token"
)

// TokenStream post-processes lexer output for consumption by the parser.
type TokenStream struct {
	lexer    Lexer
	listener Listener // for ingesting tokens into the AST, nil during lookaheads
	pending  []symbol
}

type symbol struct {
	symbol    int32
	offset    int
	endoffset int
}

func (s *TokenStream) Init(content string, l Listener) {
	s.lexer.Init(content)
	s.listener = l

	if cap(s.pending) < startTokenBufferSize {
		s.pending = make([]symbol, 0, startTokenBufferSize)
	}
	s.pending = s.pending[:0]
}

func (s *TokenStream) Copy() TokenStream {
	ret := *s
	ret.lexer = s.lexer.Copy()
	ret.listener = nil
	ret.pending = nil
	return ret
}

func (s *TokenStream) reportIgnored(ctx context.Context, tok symbol) {
	var t NodeType
	switch token.Type(tok.symbol) {
	case token.INVALID_TOKEN:
		t = InvalidToken
	case token.MULTILINECOMMENT:
		t = MultilineComment
	case token.COMMENT:
		t = Comment
	case token.TEMPLATES:
		t = Templates
	default:
		return
	}
	if debugSyntax {
		fmt.Printf("ignored: %v as %v\n", token.Type(tok.symbol), t)
	}
	s.listener(t, tok.offset, tok.endoffset)
}

// flush reports all pending tokens up to a given symbol.
func (s *TokenStream) flush(ctx context.Context, sym symbol) {
	if len(s.pending) > 0 && s.listener != nil {
		for i, tok := range s.pending {
			if tok.endoffset > sym.endoffset {
				// Note: this copying should not happen during normal operation, only
				// during error recovery.
				s.pending = append(s.pending[:0], s.pending[i:]...)
				return
			}
			s.reportIgnored(ctx, tok)
		}
		s.pending = s.pending[:0]
	}
}

func (s *TokenStream) text(sym symbol) string {
	return s.lexer.source[sym.offset:sym.endoffset]
}

func (s *TokenStream) line() int {
	return s.lexer.tokenLine
}

// next transforms the lexer stream into a stream of symbols for the parser.
//
// Note: "stack" and "endState" are nil and -1 respectively during lookaheads
// and error recovery.
func (s *TokenStream) next(stack []stackEntry, endState int16) symbol {
restart:
	tok := s.lexer.Next()
	switch tok {
	case token.INVALID_TOKEN, token.MULTILINECOMMENT, token.COMMENT, token.TEMPLATES:
		start, end := s.lexer.Pos()
		s.pending = append(s.pending, symbol{int32(tok), start, end})
		goto restart
	}
	start, end := s.lexer.Pos()
	return symbol{int32(tok), start, end}
}
