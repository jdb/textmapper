// generated by Textmapper; DO NOT EDIT

package tm

import (
	"context"
	"fmt"

	"github.com/inspirer/textmapper/parsers/tm/token"
)

// ErrorHandler is called every time a parser is unable to process some part of the input.
// This handler can return false to abort the parser.
type ErrorHandler func(err SyntaxError) bool

// StopOnFirstError is an error handler that forces the parser to stop on and return the first
// error.
func StopOnFirstError(_ SyntaxError) bool { return false }

// Parser is a table-driven LALR parser for tm.
type Parser struct {
	eh       ErrorHandler
	listener Listener

	next       symbol
	recovering int
}

type SyntaxError struct {
	Line      int
	Offset    int
	Endoffset int
}

func (e SyntaxError) Error() string {
	return fmt.Sprintf("syntax error at line %v", e.Line)
}

type stackEntry struct {
	sym   symbol
	state int16
}

func (p *Parser) Init(eh ErrorHandler, l Listener) {
	p.eh = eh
	p.listener = l
}

const (
	startStackSize       = 256
	startTokenBufferSize = 16
	noToken              = int32(token.UNAVAILABLE)
	eoiToken             = int32(token.EOI)
	debugSyntax          = false
)

func (p *Parser) ParseFile(ctx context.Context, stream *TokenStream) error {
	return p.parse(ctx, 0, 632, stream)
}

func (p *Parser) ParseNonterm(ctx context.Context, stream *TokenStream) error {
	return p.parse(ctx, 1, 633, stream)
}

func (p *Parser) parse(ctx context.Context, start, end int16, stream *TokenStream) error {
	var shiftCounter int

	state := start
	var lastErr SyntaxError
	p.recovering = 0

	var alloc [startStackSize]stackEntry
	stack := append(alloc[:0], stackEntry{state: state})
	p.next = stream.next(stack, end)

	for state != end {
		action := tmAction[state]
		if action > tmActionBase {
			// Lookahead is needed.
			if p.next.symbol == noToken {
				p.next = stream.next(stack, end)
			}
			pos := action + p.next.symbol
			if pos >= 0 && pos < tmTableLen && int32(tmCheck[pos]) == p.next.symbol {
				action = int32(tmTable[pos])
			} else {
				action = tmDefAct[state]
			}
		} else {
			action = tmDefAct[state]
		}

		if action >= 0 {
			// Reduce.
			rule := action
			ln := int(tmRuleLen[rule])

			var entry stackEntry
			entry.sym.symbol = tmRuleSymbol[rule]
			rhs := stack[len(stack)-ln:]
			for ln > 0 && rhs[ln-1].sym.offset == rhs[ln-1].sym.endoffset {
				ln--
			}
			if ln == 0 {
				if p.next.symbol == noToken {
					p.next = stream.next(stack, end)
				}
				entry.sym.offset, entry.sym.endoffset = p.next.offset, p.next.offset
			} else {
				entry.sym.offset = rhs[0].sym.offset
				entry.sym.endoffset = rhs[ln-1].sym.endoffset
			}
			if err := p.applyRule(ctx, rule, &entry, stack, stream); err != nil {
				return err
			}
			stack = stack[:len(stack)-len(rhs)]
			if debugSyntax {
				fmt.Printf("reduced to: %v\n", symbolName(entry.sym.symbol))
			}
			state = gotoState(stack[len(stack)-1].state, entry.sym.symbol)
			entry.state = state
			stack = append(stack, entry)

		} else if action < -1 {
			if shiftCounter++; shiftCounter&0x1ff == 0 {
				// Note: checking for context cancellation is expensive so we do it from time to time.
				select {
				case <-ctx.Done():
					return ctx.Err()
				default:
				}
			}

			// Shift.
			state = int16(-2 - action)
			stack = append(stack, stackEntry{
				sym:   p.next,
				state: state,
			})
			if debugSyntax {
				fmt.Printf("shift: %v (%s)\n", symbolName(p.next.symbol), stream.text(p.next))
			}
			stream.flush(ctx, p.next)
			if p.next.symbol != eoiToken {
				p.next.symbol = noToken
			}
			if p.recovering > 0 {
				p.recovering--
			}
		}

		if action == -1 || state == -1 {
			if p.recovering == 0 {
				if p.next.symbol == noToken {
					p.next = stream.next(stack, end)
				}
				lastErr = SyntaxError{
					Line:      stream.line(),
					Offset:    p.next.offset,
					Endoffset: p.next.endoffset,
				}
				if !p.eh(lastErr) {
					stream.flush(ctx, p.next)
					return lastErr
				}
			}

			p.recovering = 4
			stack = p.recoverFromError(ctx, stream, stack, end)
			if stack == nil {
				stream.flush(ctx, p.next)
				return lastErr
			}
			state = stack[len(stack)-1].state
		}
	}

	return nil
}

const errSymbol = 40

// reduceAll simulates all pending reductions and returns true if the parser
// can consume the next token in the `stack+[state]` parsing stack. This
// function also returns the state of the parser after the reductions have been
// applied (but before symbol is shifted).
func reduceAll(stack []stackEntry, state int16, symbol int32, endState int16) (int16, bool) {
	if symbol == noToken {
		panic("a valid next token is expected")
	}
	if state < 0 {
		return 0, false
	}

	var stack2alloc [4]int16
	stack2 := append(stack2alloc[:0], state)
	size := len(stack)

	// parsing_stack = stack[:size] + stack2
	for state != endState {
		action := tmAction[state]
		if action > tmActionBase {
			pos := action + symbol
			if pos >= 0 && pos < tmTableLen && int32(tmCheck[pos]) == symbol {
				action = int32(tmTable[pos])
			} else {
				action = tmDefAct[state]
			}
		} else {
			action = tmDefAct[state]
		}

		if action >= 0 {
			// Reduce.
			rule := action
			ln := int(tmRuleLen[rule])
			symbol := tmRuleSymbol[rule]

			if ln > 0 {
				if ln < len(stack2) {
					state = stack2[len(stack2)-ln-1]
					stack2 = stack2[:len(stack2)-ln]
				} else {
					size -= ln - len(stack2)
					state = stack[size-1].state
					stack2 = stack2alloc[:0]
				}
			}
			state = gotoState(state, symbol)
			stack2 = append(stack2, state)
		} else {
			return state, action < -1
		}
	}
	return state, symbol == eoiToken
}

func (p *Parser) skipBrokenCode(ctx context.Context, stream *TokenStream, canRecover func(symbol int32) bool) int {
	var e int
	for p.next.symbol != eoiToken && !canRecover(p.next.symbol) {
		if debugSyntax {
			fmt.Printf("skipped while recovering: %v (%s)\n", symbolName(p.next.symbol), stream.text(p.next))
		}
		stream.flush(ctx, p.next)
		e = p.next.endoffset
		p.next = stream.next(nil, -1)
	}
	return e
}

func (p *Parser) recoverFromError(ctx context.Context, stream *TokenStream, stack []stackEntry, endState int16) []stackEntry {
	var recoverSyms [1 + token.NumTokens/8]uint8
	var recoverPos []int

	if debugSyntax {
		fmt.Printf("broke at %v\n", symbolName(p.next.symbol))
	}
	for size := len(stack); size > 0; size-- {
		if gotoState(stack[size-1].state, errSymbol) == -1 {
			continue
		}
		recoverPos = append(recoverPos, size)
		if recoveryScopeStates[int(stack[size-1].state)] {
			break
		}
	}
	if len(recoverPos) == 0 {
		return nil
	}

	for _, v := range afterErr {
		recoverSyms[v/8] |= 1 << uint32(v%8)
	}
	canRecover := func(symbol int32) bool {
		return recoverSyms[symbol/8]&(1<<uint32(symbol%8)) != 0
	}
	if p.next.symbol == noToken {
		p.next = stream.next(stack, endState)
	}
	// By default, insert 'error' in front of the next token.
	s := p.next.offset
	e := s
	for _, tok := range stream.pending {
		// Try to cover all nearby invalid tokens.
		if token.Type(tok.symbol) == token.INVALID_TOKEN {
			if s > tok.offset {
				s = tok.offset
			}
			e = tok.endoffset
		}
	}
	for {
		if endoffset := p.skipBrokenCode(ctx, stream, canRecover); endoffset > e {
			e = endoffset
		}

		var matchingPos int
		if debugSyntax {
			fmt.Printf("trying to recover on %v\n", symbolName(p.next.symbol))
		}
		for _, pos := range recoverPos {
			if _, ok := reduceAll(stack[:pos], gotoState(stack[pos-1].state, errSymbol), p.next.symbol, endState); ok {
				matchingPos = pos
				break
			}
		}
		if matchingPos == 0 {
			if p.next.symbol == eoiToken {
				return nil
			}
			recoverSyms[p.next.symbol/8] &^= 1 << uint32(p.next.symbol%8)
			continue
		}

		if matchingPos < len(stack) {
			if s == e {
				// Avoid producing syntax problems covering trailing whitespace.
				e = stack[len(stack)-1].sym.endoffset
			}
			s = stack[matchingPos].sym.offset
		}
		if s != e {
			// Try to cover all trailing invalid tokens.
			for _, tok := range stream.pending {
				if token.Type(tok.symbol) == token.INVALID_TOKEN && tok.endoffset > e {
					e = tok.endoffset
				}
			}
		}
		if debugSyntax {
			for i := len(stack) - 1; i >= matchingPos; i-- {
				fmt.Printf("dropped from stack: %v\n", symbolName(stack[i].sym.symbol))
			}
			fmt.Println("recovered")
		}
		stream.flush(ctx, symbol{errSymbol, s, e})
		stack = append(stack[:matchingPos], stackEntry{
			sym:   symbol{errSymbol, s, e},
			state: gotoState(stack[matchingPos-1].state, errSymbol),
		})
		return stack
	}
}

func gotoState(state int16, symbol int32) int16 {
	const numTokens = 83
	if symbol >= numTokens {
		pos := tmGoto[symbol-numTokens] + int32(state)
		if pos >= 0 && pos < tmTableLen && tmCheck[pos] == int16(state) {
			return int16(tmTable[pos])
		}
		return int16(tmDefGoto[symbol-numTokens])
	}

	// Shifting a token.
	action := tmAction[state]
	if action == tmActionBase {
		return -1
	}
	pos := action + symbol
	if pos >= 0 && pos < tmTableLen && tmCheck[pos] == int16(symbol) {
		action = int32(tmTable[pos])
	} else {
		action = tmDefAct[state]
	}
	if action < -1 {
		return int16(-2 - action)
	}
	return -1
}

func (p *Parser) applyRule(ctx context.Context, rule int32, lhs *stackEntry, stack []stackEntry, stream *TokenStream) (err error) {
	switch rule {
	case 233: // nonterm : 'extend' identifier nonterm_alias reportClause ':' rules ';'
		p.reportRange(Extend, stack[len(stack)-7:len(stack)-6])
	case 234: // nonterm : 'extend' identifier nonterm_alias ':' rules ';'
		p.reportRange(Extend, stack[len(stack)-6:len(stack)-5])
	case 235: // nonterm : 'extend' identifier reportClause ':' rules ';'
		p.reportRange(Extend, stack[len(stack)-6:len(stack)-5])
	case 236: // nonterm : 'extend' identifier ':' rules ';'
		p.reportRange(Extend, stack[len(stack)-5:len(stack)-4])
	case 237: // nonterm : 'inline' identifier nonterm_params nonterm_alias reportClause ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-8:len(stack)-7])
	case 238: // nonterm : 'inline' identifier nonterm_params nonterm_alias ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-7:len(stack)-6])
	case 239: // nonterm : 'inline' identifier nonterm_params reportClause ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-7:len(stack)-6])
	case 240: // nonterm : 'inline' identifier nonterm_params ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-6:len(stack)-5])
	case 241: // nonterm : 'inline' identifier nonterm_alias reportClause ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-7:len(stack)-6])
	case 242: // nonterm : 'inline' identifier nonterm_alias ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-6:len(stack)-5])
	case 243: // nonterm : 'inline' identifier reportClause ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-6:len(stack)-5])
	case 244: // nonterm : 'inline' identifier ':' rules ';'
		p.reportRange(Inline, stack[len(stack)-5:len(stack)-4])
	case 257: // directive : '%' 'assert' 'empty' rhsSet ';'
		p.reportRange(Empty, stack[len(stack)-3:len(stack)-2])
	case 258: // directive : '%' 'assert' 'nonempty' rhsSet ';'
		p.reportRange(NonEmpty, stack[len(stack)-3:len(stack)-2])
	case 267: // inputref : symref 'no-eoi'
		p.reportRange(NoEoi, stack[len(stack)-1:len(stack)-0])
	case 306: // lookahead_predicate : '!' symref
		p.reportRange(Not, stack[len(stack)-2:len(stack)-1])
	}
	if nt := tmRuleType[rule]; nt != 0 {
		p.listener(nt, lhs.sym.offset, lhs.sym.endoffset)
	}
	return
}

func (p *Parser) reportRange(t NodeType, rhs []stackEntry) {
	for len(rhs) > 1 && rhs[len(rhs)-1].sym.offset == rhs[len(rhs)-1].sym.endoffset {
		rhs = rhs[:len(rhs)-1]
	}
	p.listener(t, rhs[0].sym.offset, rhs[len(rhs)-1].sym.endoffset)
}
